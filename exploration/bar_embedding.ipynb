{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as tdata\n",
    "import torch.utils.tensorboard as tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(sys.path[0] + \"/..\")\n",
    "import models.bar_embedding as bemb\n",
    "import models.rnn_gan as rnn_gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'models.rnn_gan' from '/home/ignacy/dev/py/mir/exploration/../models/rnn_gan.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(bemb)\n",
    "importlib.reload(rnn_gan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = bemb.Dataset.from_file(\"../data/measures/esac.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = tb.SummaryWriter(\"../runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(x: torch.Tensor, gt: torch.Tensor, decoder: bemb.Decoder, encoder: bemb.Encoder):\n",
    "    decoder.eval()\n",
    "    encoder.eval()\n",
    "    o: torch.Tensor\n",
    "    n: torch.Tensor\n",
    "    d: torch.Tensor\n",
    "\n",
    "    with torch.no_grad():\n",
    "        o, n, d = decoder(encoder(x))\n",
    "\n",
    "    oo = o.argmax(dim=2)\n",
    "    nn = n.argmax(dim=2)\n",
    "    dd = d.argmax(dim=2)\n",
    "\n",
    "    gt_lens = torch.tensor([(gt[i, :, 0] == 0).nonzero()[0] for i in range(gt.shape[0])])\n",
    "    oo_lens = torch.tensor([(oo[i] == 0).nonzero()[0] for i in range(gt.shape[0])])\n",
    "    nn_lens = torch.tensor([(nn[i] == 0).nonzero()[0] for i in range(gt.shape[0])])\n",
    "    dd_lens = torch.tensor([(dd[i] == 0).nonzero()[0] for i in range(gt.shape[0])])\n",
    "\n",
    "    len_hit_rate = ((gt_lens == oo_lens).sum() + (gt_lens == nn_lens).sum() + (gt_lens == dd_lens).sum()) / (3 * gt.shape[0])\n",
    "\n",
    "    ogt = gt[:, :, 0] > 1\n",
    "    ngt = gt[:, :, 1] > 1\n",
    "    dgt = gt[:, :, 2] > 1\n",
    "\n",
    "    octave_hit_rate = (oo[ogt] == gt[:, :, 0][ogt]).sum() / ogt.sum()\n",
    "    note_hit_rate = (nn[ngt] == gt[:, :, 1][ngt]).sum() / ngt.sum()\n",
    "    duration_hit_rate = (dd[dgt] == gt[:, :, 2][dgt]).sum() / dgt.sum()\n",
    "\n",
    "    cmp = torch.stack([oo, nn, dd], dim=2) == gt\n",
    "    bar_hit_rate = (cmp.sum(dim=2).sum(dim=1) == gt.shape[1] * gt.shape[2]).sum() / gt.shape[0]\n",
    "\n",
    "    return len_hit_rate, octave_hit_rate, note_hit_rate, duration_hit_rate, bar_hit_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 97589)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "idxs = list(range(len(dataset)))\n",
    "random.shuffle(idxs)\n",
    "eval_idxs = idxs[:10_000]\n",
    "train_idxs = idxs[10_000:]\n",
    "len(eval_idxs), len(train_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "bars = dataset.bars\n",
    "bars_octavised = dataset.bars_octavised\n",
    "eval_bars = itemgetter(*eval_idxs)(bars)\n",
    "eval_bars_octavised = itemgetter(*eval_idxs)(bars_octavised)\n",
    "train_bars = itemgetter(*train_idxs)(bars)\n",
    "train_bars_octavised = itemgetter(*train_idxs)(bars_octavised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "\n",
    "train_dataset = copy(dataset)\n",
    "eval_dataset = copy(dataset)\n",
    "\n",
    "train_dataset.bars = train_bars\n",
    "train_dataset.bars_octavised = train_bars_octavised\n",
    "\n",
    "eval_dataset.bars = eval_bars\n",
    "eval_dataset.bars_octavised = eval_bars_octavised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 16, 2]) torch.Size([10000, 16, 3])\n",
      "torch.Size([10000, 16, 2]) torch.Size([10000, 16, 3])\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "epoch: 3\n",
      "epoch: 4\n",
      "epoch: 5\n",
      "epoch: 6\n",
      "epoch: 7\n",
      "epoch: 8\n",
      "epoch: 9\n",
      "epoch: 10\n",
      "epoch: 11\n",
      "epoch: 12\n",
      "epoch: 13\n",
      "epoch: 14\n",
      "epoch: 15\n",
      "epoch: 16\n",
      "epoch: 17\n",
      "epoch: 18\n",
      "epoch: 19\n",
      "epoch: 20\n",
      "epoch: 21\n",
      "epoch: 22\n",
      "epoch: 23\n",
      "epoch: 24\n",
      "epoch: 25\n",
      "epoch: 26\n",
      "epoch: 27\n",
      "epoch: 28\n",
      "epoch: 29\n",
      "epoch: 30\n",
      "epoch: 31\n",
      "epoch: 32\n",
      "epoch: 33\n",
      "epoch: 34\n",
      "epoch: 35\n",
      "epoch: 36\n",
      "epoch: 37\n",
      "epoch: 38\n",
      "epoch: 39\n",
      "epoch: 40\n",
      "epoch: 41\n",
      "epoch: 42\n",
      "epoch: 43\n",
      "epoch: 44\n",
      "epoch: 45\n",
      "epoch: 46\n",
      "epoch: 47\n",
      "epoch: 48\n",
      "epoch: 49\n",
      "epoch: 50\n",
      "epoch: 51\n",
      "epoch: 52\n",
      "epoch: 53\n",
      "epoch: 54\n",
      "epoch: 55\n",
      "epoch: 56\n",
      "epoch: 57\n",
      "epoch: 58\n",
      "epoch: 59\n",
      "epoch: 60\n",
      "epoch: 61\n",
      "epoch: 62\n",
      "epoch: 63\n",
      "epoch: 64\n",
      "epoch: 65\n",
      "epoch: 66\n",
      "epoch: 67\n",
      "epoch: 68\n",
      "epoch: 69\n",
      "epoch: 70\n",
      "epoch: 71\n",
      "epoch: 72\n",
      "epoch: 73\n",
      "epoch: 74\n",
      "epoch: 75\n",
      "epoch: 76\n",
      "epoch: 77\n",
      "epoch: 78\n",
      "epoch: 79\n",
      "epoch: 80\n",
      "epoch: 81\n",
      "epoch: 82\n",
      "epoch: 83\n",
      "epoch: 84\n",
      "epoch: 85\n",
      "epoch: 86\n",
      "epoch: 87\n",
      "epoch: 88\n",
      "epoch: 89\n",
      "epoch: 90\n",
      "epoch: 91\n",
      "epoch: 92\n",
      "epoch: 93\n",
      "epoch: 94\n",
      "epoch: 95\n",
      "epoch: 96\n",
      "epoch: 97\n",
      "epoch: 98\n",
      "epoch: 99\n",
      "epoch: 100\n"
     ]
    }
   ],
   "source": [
    "encoder = bemb.Encoder(\n",
    "    pitch_vocab_count=50,\n",
    "    duration_vocab_count=25,\n",
    "    pitch_embedding_dim=16,\n",
    "    duration_embedding_dim=16,\n",
    "    bar_len=16,\n",
    "    bar_embedding_len=6,\n",
    "    out_dim=64\n",
    ")\n",
    "\n",
    "decoder = bemb.Decoder(\n",
    "    in_dimension=64,\n",
    "    octave_vocab=6,\n",
    "    bar_len=16,\n",
    "    duration_vocab=25,\n",
    ")\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "train_dataloader = tdata.DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=0.001)\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=0.001)\n",
    "\n",
    "dataloader_for_train_eval = tdata.DataLoader(train_dataset, batch_size=10_000, shuffle=True)\n",
    "train_eval_data = next(iter(dataloader_for_train_eval))\n",
    "dataloader_for_eval_eval = tdata.DataLoader(eval_dataset, batch_size=10_000)\n",
    "eval_eval_data = next(iter(dataloader_for_eval_eval))\n",
    "print(train_eval_data[0].shape, train_eval_data[1].shape)\n",
    "print(eval_eval_data[0].shape, eval_eval_data[1].shape)\n",
    "\n",
    "info_step = 1000\n",
    "running_loss_octave = 0\n",
    "running_loss_note = 0\n",
    "running_loss_duration = 0\n",
    "global_step = 0\n",
    "\n",
    "\n",
    "for epoch in range(100):\n",
    "    print(\"epoch:\", epoch + 1)\n",
    "    for x, y in train_dataloader:\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "\n",
    "        encoder.zero_grad()\n",
    "        decoder.zero_grad()\n",
    "\n",
    "        encoded = encoder.forward(x)\n",
    "        o, n, d = decoder.forward(encoded)\n",
    "\n",
    "        loss_octave = criterion(o.swapaxes(1, 2), y[:, :, 0])\n",
    "        loss_note = criterion(n.swapaxes(1, 2), y[:, :, 1])\n",
    "        loss_duration = criterion(d.swapaxes(1, 2), y[:, :, 2])\n",
    "        loss: torch.Tensor = loss_octave + loss_note + loss_duration * 3\n",
    "        loss.backward()\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "        running_loss_octave += loss_octave\n",
    "        running_loss_note += loss_note\n",
    "        running_loss_duration += loss_duration\n",
    "\n",
    "        if global_step % info_step == info_step - 1:\n",
    "            avg_loss_octave = running_loss_octave / info_step\n",
    "            avg_loss_note = running_loss_note / info_step\n",
    "            avg_loss_duration = running_loss_duration / info_step\n",
    "            writer.add_scalar(\"loss/avg_octave\", avg_loss_octave.item(), global_step)\n",
    "            writer.add_scalar(\"loss/avg_note\", avg_loss_note.item(), global_step)\n",
    "            writer.add_scalar(\"loss/avg_duration\", avg_loss_duration.item(), global_step)\n",
    "            running_loss_octave = 0\n",
    "            running_loss_note = 0\n",
    "            running_loss_duration = 0\n",
    "\n",
    "            len_hit_rate, octave_hit_rate, note_hit_rate, duration_hit_rate, bar_hit_rate = eval(*train_eval_data, decoder, encoder)\n",
    "            writer.add_scalar(\"hit_rate_train/len\", len_hit_rate, global_step)\n",
    "            writer.add_scalar(\"hit_rate_train/octave\", octave_hit_rate, global_step)\n",
    "            writer.add_scalar(\"hit_rate_train/note\", note_hit_rate, global_step)\n",
    "            writer.add_scalar(\"hit_rate_train/duration\", duration_hit_rate, global_step)\n",
    "            writer.add_scalar(\"hit_rate_train/bar\", bar_hit_rate, global_step)\n",
    "\n",
    "            len_hit_rate, octave_hit_rate, note_hit_rate, duration_hit_rate, bar_hit_rate = eval(*eval_eval_data, decoder, encoder)\n",
    "            writer.add_scalar(\"hit_rate_eval/len\", len_hit_rate, global_step)\n",
    "            writer.add_scalar(\"hit_rate_eval/octave\", octave_hit_rate, global_step)\n",
    "            writer.add_scalar(\"hit_rate_eval/note\", note_hit_rate, global_step)\n",
    "            writer.add_scalar(\"hit_rate_eval/duration\", duration_hit_rate, global_step)\n",
    "            writer.add_scalar(\"hit_rate_eval/bar\", bar_hit_rate, global_step)\n",
    "\n",
    "        global_step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.2916), tensor(0.5000), tensor(0.0995), tensor(0.0621), tensor(0.))"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader_for_eval = tdata.DataLoader(dataset, batch_size=10000, shuffle=True)\n",
    "eval_data = next(iter(dataloader_for_eval))\n",
    "eval(*eval_data, decoder, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[26, 23, 31, 28,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [10, 10,  7,  7,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]]])\n",
      "tensor([[[ 4,  3,  4,  4,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [ 2, 11,  7,  4,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [10, 10,  7,  7,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]]])\n",
      "tensor([[[ 4,  3,  4,  4,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [ 2, 11,  7,  4,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [10, 10,  7,  7,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]]])\n"
     ]
    }
   ],
   "source": [
    "i = 9\n",
    "xx = x[i:i+1]\n",
    "mask = xx > 1\n",
    "xx[0, 0, 1]\n",
    "yy = y[i:i+1]\n",
    "print(xx.transpose(1, 2))\n",
    "print(yy.transpose(1, 2))\n",
    "\n",
    "latent = encoder(xx)\n",
    "o, n, d = decoder(latent)\n",
    "print(torch.stack([o.argmax(dim=2), n.argmax(dim=2), d.argmax(dim=2)]).swapaxes(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 4,  3,  4,  4,  3,  4,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [ 2, 11,  7,  2, 11,  7,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [10, 10,  7, 10, 10,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]]])\n"
     ]
    }
   ],
   "source": [
    "xxx = torch.concat([xx[:, :3, :], xx[:, :3, :], xx[:, 6:, :]], dim=1)\n",
    "latent = encoder(xxx)\n",
    "o, n, d = decoder(latent)\n",
    "print(torch.stack([o.argmax(dim=2), n.argmax(dim=2), d.argmax(dim=2)]).swapaxes(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 3,  1,  3,  1,  3,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [ 2,  1,  5,  4, 13,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [ 7,  4,  7,  7,  7,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]]])\n"
     ]
    }
   ],
   "source": [
    "random_latent = torch.rand_like(latent)\n",
    "# latent_modified = torch\n",
    "o, n, d = decoder(random_latent)\n",
    "print(torch.stack([o.argmax(dim=2), n.argmax(dim=2), d.argmax(dim=2)]).swapaxes(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"../models/serialized/bar_embedding/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.save(encoder.state_dict(), f\"{PATH}encoder-v02.pt\")\n",
    "torch.save(decoder.state_dict(), f\"{PATH}decoder-v02.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bar_encoder = bemb.Encoder(\n",
    "    pitch_vocab_count=50,\n",
    "    duration_vocab_count=25,\n",
    "    pitch_embedding_dim=16,\n",
    "    duration_embedding_dim=16,\n",
    "    bar_len=16,\n",
    "    bar_embedding_len=4,\n",
    "    out_dim=64\n",
    ")\n",
    "\n",
    "bar_decoder = bemb.Decoder(\n",
    "    in_dimension=64,\n",
    "    octave_vocab=6,\n",
    "    bar_len=16,\n",
    "    duration_vocab=25,\n",
    ")\n",
    "\n",
    "bar_encoder.load_state_dict(torch.load(f\"{PATH}encoder-v01.pt\")) \n",
    "bar_decoder.load_state_dict(torch.load(f\"{PATH}decoder-v01.pt\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = rnn_gan.Generator(64, random_dim=64, hidden_dim=64, num_layers=2, bidirectional=True)\n",
    "discriminator = rnn_gan.Discriminator(64, hidden_dim=64, num_layers=2, bidirectional=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = rnn_gan.Trainer(\n",
    "    generator=generator,\n",
    "    discriminator=discriminator,\n",
    "    generator_optimizer=torch.optim.Adam(generator.parameters(), lr=0.001),\n",
    "    discriminator_optimizer=torch.optim.Adam(discriminator.parameters(), lr=0.001),\n",
    ")\n",
    "\n",
    "\n",
    "FAKE_LABEL = 0.0\n",
    "REAL_LABEL = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = tb.SummaryWriter(\"../runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [74], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m lens \u001b[39m=\u001b[39m [\u001b[39m1\u001b[39m] \u001b[39m*\u001b[39m x_embedded\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m     11\u001b[0m \u001b[39mif\u001b[39;00m global_step \u001b[39m%\u001b[39m \u001b[39m3\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> 12\u001b[0m     info \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mtrain_on_batch(x_embedded, lens, train_discriminator\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     14\u001b[0m     mean_preds_real \u001b[39m=\u001b[39m info\u001b[39m.\u001b[39mpreds_real\u001b[39m.\u001b[39mmean()\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     15\u001b[0m     mean_preds_fake \u001b[39m=\u001b[39m info\u001b[39m.\u001b[39mpreds_fake\u001b[39m.\u001b[39mmean()\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/dev/py/mir/exploration/../models/rnn_gan.py:186\u001b[0m, in \u001b[0;36mTrainer.train_on_batch\u001b[0;34m(self, x_real, x_lens, train_discriminator, train_generator)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdiscriminator\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m    184\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerator\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m--> 186\u001b[0m loss_on_fake, loss_on_real, preds_fake, preds_real \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_discriminator(\n\u001b[1;32m    187\u001b[0m     x_real, x_lens, train_discriminator\n\u001b[1;32m    188\u001b[0m )\n\u001b[1;32m    190\u001b[0m generator_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_generator(x_real, x_lens, train_generator)\n\u001b[1;32m    192\u001b[0m \u001b[39mreturn\u001b[39;00m Trainer\u001b[39m.\u001b[39mInfo(\n\u001b[1;32m    193\u001b[0m     generator_loss\u001b[39m=\u001b[39mgenerator_loss,\n\u001b[1;32m    194\u001b[0m     discriminator_loss_on_fake\u001b[39m=\u001b[39mloss_on_fake,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    197\u001b[0m     preds_real\u001b[39m=\u001b[39mpreds_real,\n\u001b[1;32m    198\u001b[0m )\n",
      "File \u001b[0;32m~/dev/py/mir/exploration/../models/rnn_gan.py:226\u001b[0m, in \u001b[0;36mTrainer.train_discriminator\u001b[0;34m(self, x_real, x_lens, train_discriminator)\u001b[0m\n\u001b[1;32m    220\u001b[0m preds_fake: torch\u001b[39m.\u001b[39mTensor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdiscriminator\u001b[39m.\u001b[39mforward(\n\u001b[1;32m    221\u001b[0m     x_fake, [x_fake\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]] \u001b[39m*\u001b[39m x_fake\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m    222\u001b[0m )\n\u001b[1;32m    223\u001b[0m loss_discr_on_fake: torch\u001b[39m.\u001b[39mTensor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcriterion(\n\u001b[1;32m    224\u001b[0m     preds_fake, torch\u001b[39m.\u001b[39mones_like(preds_real) \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mFAKE_LABEL\n\u001b[1;32m    225\u001b[0m )\n\u001b[0;32m--> 226\u001b[0m loss_discr_on_fake\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m    228\u001b[0m \u001b[39m# update discriminator params\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdiscriminator_optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_dataloader = tdata.DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "global_step = 0\n",
    "discr_train = True\n",
    "for epoch in range(5):\n",
    "    for x, y in train_dataloader:\n",
    "        with torch.no_grad():\n",
    "            x_embedded = bar_encoder.forward(x).unsqueeze(dim=1)\n",
    "        \n",
    "        lens = [1] * x_embedded.shape[0]\n",
    "\n",
    "        if global_step % 2 == 0:\n",
    "            info = trainer.train_on_batch(x_embedded, lens, train_discriminator=True)\n",
    "\n",
    "            mean_preds_real = info.preds_real.mean().item()\n",
    "            mean_preds_fake = info.preds_fake.mean().item()\n",
    "            writer.add_scalar(\"preds/real_prediction\", mean_preds_real, global_step)\n",
    "            writer.add_scalar(\"preds/fake_prediction\", mean_preds_fake, global_step)\n",
    "            writer.add_scalar(\"preds/total\", (mean_preds_real + 1 - mean_preds_fake) / 2, global_step)\n",
    "\n",
    "            writer.add_scalar(\"loss/fake_discriminator\", info.discriminator_loss_on_fake, global_step)\n",
    "            writer.add_scalar(\"loss/real_discriminator\", info.discriminator_loss_on_real, global_step)\n",
    "            writer.add_scalar(\"loss/generator\", info.generator_loss, global_step)\n",
    "        else:\n",
    "            info = trainer.train_on_batch(x_embedded, lens, train_discriminator=False)\n",
    "\n",
    "\n",
    "        global_step += 1\n",
    "    \n",
    "    print(\"#########################################################\")\n",
    "    print(f\"FINISHED epoch {epoch + 1}\")\n",
    "    print()\n",
    "    x = generator.forward(1, 10)\n",
    "    o, n, d = bar_decoder(x)\n",
    "    print(torch.stack([o.argmax(dim=2), n.argmax(dim=2), d.argmax(dim=2)]).swapaxes(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  9.1616, -12.2715,  -2.4066,  -8.0539,   2.9918,  -4.1237,  -6.2514,\n",
       "          10.8658,   3.6993,   2.2424,  -3.1121,  -7.4591,  -0.6807,  10.1481,\n",
       "          -5.2742,  -7.8294,   4.0995,   4.0384,  -4.4606,   2.9805,   6.5055,\n",
       "          -1.5825,  -6.9742,  -5.7228,  -3.4613,   8.4375,   0.1333,   1.3639,\n",
       "           3.9939,  -4.5048,  -5.9342,  -3.5237,  -8.4318,   1.7535,   9.5841,\n",
       "           2.8032,  -2.1260, -11.1933,   1.0091,  -1.9871,  -1.0478,  -6.7105,\n",
       "          -4.1099,  -1.1519,  -4.1499,   8.0925,  -6.2305,   0.9304,  20.5449,\n",
       "          -0.6710,   5.7573,  -4.6482,  -3.4319,  -3.5472,  -7.6333,   3.7415,\n",
       "          -1.5738,   5.4126,   1.1595,  -5.7752,   5.2639,  -3.2532, -11.5777,\n",
       "          -3.6738]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x = generator.forward(1, 1)\n",
    "# o, n, d = bar_decoder(x)\n",
    "# print(torch.stack([o.argmax(dim=2), n.argmax(dim=2), d.argmax(dim=2)]).swapaxes(0, 1))\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[26, 25, 21, 23, 21, 23,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [10,  7,  7,  7,  7, 10,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]],\n",
      "\n",
      "        [[28, 26, 24, 26, 28, 25, 23, 26,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [ 7,  7,  7,  7,  7,  7,  7,  7,  0,  0,  0,  0,  0,  0,  0,  0]],\n",
      "\n",
      "        [[24, 19, 24,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [ 7,  7,  7,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]],\n",
      "\n",
      "        [[13, 14, 18, 16, 14,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [ 7,  4,  4,  4,  4,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]],\n",
      "\n",
      "        [[23, 26, 26,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [ 4,  4,  4,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]],\n",
      "\n",
      "        [[25, 28, 24, 23,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [ 9,  4,  7,  9,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]],\n",
      "\n",
      "        [[28, 27, 25,  1, 25,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [ 4,  4,  7,  7,  7,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]],\n",
      "\n",
      "        [[24, 21, 17,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [10,  7, 10,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]],\n",
      "\n",
      "        [[26, 29, 31, 31,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [ 7,  7, 10, 10,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]],\n",
      "\n",
      "        [[23, 19, 19,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [ 7,  7, 10,  7,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for x, y in train_dataloader:\n",
    "    print(x.transpose(1, 2))\n",
    "    # o, n, d = bar_decoder(x)\n",
    "    # print(torch.stack([o.argmax(dim=2), n.argmax(dim=2), d.argmax(dim=2)]).swapaxes(0, 1))\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
